# üå™Ô∏è Desafio Delfos - ETL Pipeline

![Python](https://img.shields.io/badge/Python-3.12-blue?style=flat-square&logo=python)
![FastAPI](https://img.shields.io/badge/FastAPI-0.109-green?style=flat-square&logo=fastapi)
![Docker](https://img.shields.io/badge/Docker-Compose-2496ED?style=flat-square&logo=docker)
![Code Style](https://img.shields.io/badge/Code%20Style-Ruff-black?style=flat-square)

Este reposit√≥rio cont√©m a solu√ß√£o para o desafio t√©cnico da Delfos. O projeto implementa um pipeline completo de **Engenharia de Dados**, simulando a ingest√£o, processamento e armazenamento de s√©ries temporais geradas por sensores de energia e√≥lica.

---

## üìë Sum√°rio

1. [Sobre o Projeto](#-sobre-o-projeto)
2. [Arquitetura e Componentes](#-arquitetura-e-componentes)
3. [Stack Tecnol√≥gica](#-stack-tecnol√≥gica)
4. [Como Rodar (Docker)](#-como-rodar-o-projeto-docker)
5. [Como Rodar (Local)](#-como-rodar-localmente)
6. [Pipeline ETL](#-detalhes-do-pipeline-etl)
7. [Como Rodar os Testes](#-como-rodar-os-testes)
    * [Com Docker](#com-docker-recomendado)
    * [Localmente](#localmente-sem-docker)
8. [Decis√µes T√©cnicas](#-decis√µes-t√©cnicas)
9. [Dagster (B√¥nus)](#-dagster-b√¥nus)

---

## üìñ Sobre o Projeto

O objetivo √© orquestrar um fluxo onde dados brutos de alta frequ√™ncia (gerados a cada minuto) s√£o extra√≠dos, agregados em janelas de 10 minutos (downsampling) e normalizados para um formato anal√≠tico (Tidy Data) em um banco de dados destino.

## üèó Arquitetura e Componentes

O sistema √© modularizado em dois servi√ßos principais isolados:

*   **`fonte/`**: API RESTful constru√≠da com FastAPI e SQLAlchemy Async. Simula sensores de parques e√≥licos gerando dados de alta frequ√™ncia (minuto a minuto), expondo endpoints para consulta e gera√ß√£o de dados sint√©ticos (`seed`).
*   **`alvo/`**: O Worker de ETL respons√°vel por extrair os dados da API Fonte, transform√°-los utilizando **Pandas** (c√°lculo de m√©dia, min, max, std) e carreg√°-los em um banco PostgreSQL dedicado utilizando t√©cnicas de *Upsert*.

### Fluxo de Dados

```mermaid
flowchart LR
    subgraph "Ambiente Fonte (OLTP)"
        API[FastAPI Service]
        DB_Fonte[(Postgres Fonte)]
        API --> DB_Fonte
    end

    subgraph "Ambiente Alvo (ETL/OLAP)"
        Worker[Python ETL Worker]
        DB_Alvo[(Postgres Alvo)]

        Worker -- Extract (HTTP) --> API
        Worker -- Transform (Pandas) --> Worker
        Worker -- Load (SQLAlchemy) --> DB_Alvo
    end
```

## üõ† Stack Tecnol√≥gica

*   **Linguagem:** Python 3.12
*   **Gerenciador de Pacotes:** `uv` (pela alta performance e lockfiles confi√°veis)
*   **Web Framework:** FastAPI + Pydantic
*   **Database ORM:** SQLAlchemy 2.0 (Async) + Alembic (Migrations)
*   **Processamento de Dados:** Pandas
*   **Infraestrutura:** Docker & Docker Compose
*   **Testes:** Pytest, Asyncio, Testcontainers

---

## üöÄ Como Rodar o Projeto (Docker)

Esta √© a maneira recomendada, pois isola redes e bancos de dados.

### 1. Subir o ambiente
```bash
docker compose up -d --build
```
Isso provisionar√°:
*   `app_fonte` (API): http://localhost:8000
*   `postgres_fonte`: Porta 5433
*   `postgres_alvo`: Porta 5434
*   `app_alvo`: Container worker em modo de espera.

### 2. Popular a Fonte (Seed)
Gere dados sint√©ticos na API Fonte para simular o hist√≥rico de sensores.
Exemplo: Gerar dados para o dia 01/01/2024.

```bash
curl -X POST "http://localhost:8000/api/seed" \
     -H "Content-Type: application/json" \
     -d '{"start_date": "2024-01-01T00:00:00", "days": 1}'
```

### 3. Executar o ETL
Dispare o comando no container do worker para processar o dia desejado.

```bash
docker compose exec app_alvo python -m app.main --date 2024-01-01
```
*O script ir√° extrair os 1440 pontos de dados (minuto a minuto), agregar em janelas de 10 minutos e salvar no banco alvo.*

---

## üíª Como Rodar Localmente

Se preferir rodar fora do Docker, voc√™ precisar√° do `uv` instalado e de bancos de dados Postgres locais.

1.  **Configurar Vari√°veis de Ambiente:**
    Crie um arquivo `.env` nas pastas `fonte/` e `alvo/` apontando para seu banco local.

2.  **Instalar depend√™ncias e Rodar:**

    **Terminal 1 (Fonte):**
    ```bash
    cd fonte
    uv sync
    uv run alembic upgrade head
    uv run fastapi dev app/main.py
    ```

    **Terminal 2 (Alvo):**
    ```bash
    cd alvo
    uv sync
    uv run alembic upgrade head
    # Rodar o ETL
    uv run python -m app.main --date 2024-01-01
    ```

---

## ‚öôÔ∏è Detalhes do Pipeline ETL

1.  **Extract:** O servi√ßo consulta a API Fonte paginada por dia. Utilizamos `httpx` ass√≠ncrono para garantir performance na I/O.
2.  **Transform:**
    *   Convers√£o para DataFrame Pandas.
    *   Resample temporal de `10T` (10 minutos).
    *   C√°lculo de agrega√ß√µes: `mean`, `min`, `max`, `std`.
    *   *Unpivoting*: Transforma√ß√£o de formato largo (colunas) para formato longo (tabela `TargetData` e `Signal`).
3.  **Load:**
    *   Verifica√ß√£o e cria√ß√£o din√¢mica de novos Sinais na tabela `signal`.
    *   Inser√ß√£o em lote com tratamento de conflitos (`ON CONFLICT DO UPDATE`), garantindo idempot√™ncia (pode rodar o ETL v√°rias vezes para o mesmo dia sem duplicar dados).

---

## üß™ Como Rodar os Testes

Os testes automatizados garantem a integridade tanto da API quanto da l√≥gica de transforma√ß√£o de dados.

### Com Docker (Recomendado)

O projeto utiliza `Testcontainers` para garantir que os testes de integra√ß√£o rodem contra um banco PostgreSQL real, e n√£o mocks ou SQLite, garantindo fidelidade ao ambiente de produ√ß√£o.

Para rodar todos os testes:

```bash
# Testes da API Fonte
docker compose exec app_fonte uv run pytest

# Testes do Pipeline ETL
docker compose exec app_alvo uv run pytest
```

### Localmente (Sem Docker)
Voc√™ precisar√° do `uv` instalado e de bancos de dados Postgres rodando localmente (ou via TestContainers).

```bash
# Na pasta 'fonte/'
cd fonte
uv sync
uv run pytest

# Na pasta 'alvo/'
cd alvo
uv sync
uv run pytest
```

---

## üß† Decis√µes T√©cnicas

*   **Async/Await:** Utilizado em todo o projeto (Banco e API) para maximizar o throughput, j√° que a opera√ß√£o √© intensiva em I/O.
*   **Postgres vs Timescale:** O projeto utiliza Postgres padr√£o, mas a modelagem no Alvo (Tabela `Data` com chave composta `timestamp` + `signal_id`) foi pensada para ser compat√≠vel com hiper-tabelas do TimescaleDB no futuro.
*   **Uv Package Manager:** Escolhido pela velocidade de instala√ß√£o e resolu√ß√£o de depend√™ncias, reduzindo drasticamente o tempo de build do Docker.
*   **Entrypoints Inteligentes:** Os containers possuem scripts que garantem que as migra√ß√µes do banco (Alembic) sejam aplicadas automaticamente antes da aplica√ß√£o iniciar.

---

## üåü Dagster (B√¥nus)

Esta implementa√ß√£o √© uma **funcionalidade b√¥nus** e um **desafio de aprendizado**. O autor n√£o possui experi√™ncia pr√©via extensa com Dagster, mas incluiu esta ferramenta para demonstrar capacidade de adapta√ß√£o e aprendizado de novas tecnologias.

**Dagster** √© uma plataforma moderna de orquestra√ß√£o de dados que permite definir, agendar e monitorar pipelines de dados de forma declarativa e test√°vel.

### Como Acessar a UI

Assumindo que o servi√ßo Dagster est√° em execu√ß√£o via Docker:

```bash
# Acesse a interface web do Dagster
http://localhost:3000
```

A interface do Dagster permite visualizar o status dos pipelines, executar jobs manualmente, e monitorar o hist√≥rico de execu√ß√µes.